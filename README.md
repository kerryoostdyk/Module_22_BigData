# Module_22_BigData

# Home Sales Analysis with PySpark

This project analyzes a home sales dataset using **PySpark** in **Google Colab**. The dataset was imported from an **AWS S3 bucket**, and various transformations and queries were performed to explore data performance using caching and partitioning.

## üîß Technologies Used

- Python (Google Colab)
- PySpark
- AWS S3

## üìÇ Dataset

The home sales dataset was read directly from an S3 bucket using PySpark. 
It includes information such as sale price, location, and other house stats.

## ‚öôÔ∏è What This Project Does

- Loads a CSV dataset from AWS S3
- Creates a Spark DataFrame
- Performs data analysis (e.g. average prices)
- Creates a temporary view for SQL queries
- Caches the table to improve performance
- Partitions the data and compares query speeds
- Evaluates performance benefits of caching vs partitioning


Reference: 
Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.

